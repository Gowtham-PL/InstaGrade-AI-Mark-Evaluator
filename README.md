# ğŸ“š InstaGrade â€“ AI Mark Evaluator

InstaGrade is an AIâ€‘powered tool that automatically evaluates student answer sheets by comparing them with a teacherâ€™s answer key.  
It reads PDFs, extracts text, splits it into questionâ€‘wise answers, and then scores each answer using **semantic similarity + keyword matching** so that students can write in their own words and still be graded fairly. âœ¨

---

## ğŸš€ Features

- ğŸ” **PDF text extraction** using Azure Document Intelligence  
- âœ‚ï¸ **Smart question parsing** (supports `1)`, `1.`, `Q1`, `Q1)`, etc.)  
- ğŸ§  **Semantic answer comparison** with Sentence Transformers  
- ğŸ§¾ **Hybrid scoring**: semantic similarity + keyword overlap  
- ğŸ“ **Perâ€‘question feedback** (correctness + comments)  
- ğŸ¯ **Overall test score (0â€“100)**  
- ğŸŒ **Pluggable frontend** (web UI planned / in progress)

---

## ğŸ—ï¸ Architecture Overview

Backend is split into small, focused modules:

- `extract_text.py` â€“ Extracts raw text from student & teacher PDFs and saves JSON  
- `parse_questions_improved.py` â€“ Converts raw text into `{Q1: answer, Q2: answer, ...}` dictionaries  
- `similarity_checker.py` â€“ Cleans text and computes semantic + keyword scores  
- `feedback_marker.py` â€“ Converts scores into marks and humanâ€‘readable feedback  
- `main.py` â€“ Orchestrates the entire pipeline (extract â†’ parse â†’ grade)  
- `extracted_texts/` â€“ Stores intermediate and final JSON files

A separate **frontend** (e.g., React/Next.js) can call backend APIs to:
- upload PDFs,
- trigger the grading pipeline,
- display questionâ€‘wise breakdown, feedback, and total score.

